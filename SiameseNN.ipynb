{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelledPath = \" \" #Please provide path to labelled dataset\n",
    "UnabelledPath = \" \" #Please provide path to unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading labelled and Unlabelled datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"LabelledPath\" , \"r\")\n",
    "H = f[\"H_Est\"][:].transpose(0,3,1,2)\n",
    "Pos = f[\"Pos\"][:]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(\"UnlabelledPath\", 'r')\n",
    "X = f['H_Est'][:24000].transpose(0,3,1,2)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "H_Train, H_Test , Pos_Train , Pos_Test = train_test_split(H,Pos,test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_Train, H_Val , Pos_Train , Pos_Val = train_test_split(H_Train,Pos_Train,test_size=0.1, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_Train = torch.tensor(H_Train,dtype=torch.float)\n",
    "Pos_Train = torch.tensor(Pos_Train,dtype=torch.float)\n",
    "H_Val = torch.tensor(H_Val,dtype=torch.float)\n",
    "Pos_Val = torch.tensor(Pos_Val,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sammon(nn.Module):\n",
    "    ''' Deep Convolutional NN for Postion estimation'''\n",
    "    def __init__(self):\n",
    "        super(Sammon, self).__init__()\n",
    "        \n",
    "        '''Convolutional Layers'''\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=5, out_channels=128, kernel_size=5, padding=2) ,\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d((1,4) ),\n",
    "            nn.Conv2d(in_channels=128, out_channels=28, kernel_size=3, padding=1) ,\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d((1,4) )\n",
    "        )\n",
    "        \n",
    "        ''' Fully Connected Layers'''\n",
    "        self.Project = nn.Sequential(nn.Linear(57*56*28,1024),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(1024,512),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(512,256),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(256,128),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Linear(128,3))\n",
    "        \n",
    "          \n",
    "            \n",
    "    def forward(self, input):\n",
    "        return self.Project(self.main(input).reshape(-1,57*56*28))\n",
    "    \n",
    "class Alpha(nn.Module):\n",
    "    ''' Scaling factor for position'''\n",
    "    def __init__(self):\n",
    "        super(Alpha, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.FloatTensor(1).fill_(1));        \n",
    "            \n",
    "    def forward(self, input):\n",
    "        return self.scale*input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "sammon = Sammon().to(device)\n",
    "alpha = Alpha().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Adam Optimizers'''\n",
    "opt1 = optim.Adam(sammon.parameters(), lr=1e-3,weight_decay=1e-7)\n",
    "opt3 = optim.Adam(alpha.parameters(), lr=1e-3,weight_decay=1e-7)\n",
    "MSE  = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Generating pairs from unsupervised dataset'''\n",
    "A = list(range(len(X)))*25\n",
    "pairs = []\n",
    "import random\n",
    "while len(A)>1:\n",
    "  t = random.randint(1,len(A)-1)\n",
    "  if(A[t]!=A[0]) :\n",
    "    pairs.append((A[0],A[t]))\n",
    "    del A[0]\n",
    "    del A[t-1]\n",
    "pairs = np.array(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EucNorm(X,e=1e-6):\n",
    "      return torch.sqrt(torch.norm(X)**2 + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_b2 = len(H_Train) #No of samples in labelled training set\n",
    "N_b = len(pairs) #No of samples from unlabelled set\n",
    "N_val = len(H_Val) #No of samples for validation\n",
    "bs1= 64 #Batch Size for unsupervised learning\n",
    "bs2 = 16 #Batch Size for supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loss(XX, YY):\n",
    "    ''' Sammon Loss Function'''\n",
    "    return torch.sum((1/XX)*(torch.square(XX-YY)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Training the Model'''\n",
    "for i in range(50):\n",
    "  batch1=0\n",
    "  SammonLoss = []\n",
    "  ''' Unsupervised learning via sammon mapping'''\n",
    "  for j in range(0,N_b,bs1):\n",
    "    sammon.zero_grad()\n",
    "    alpha.zero_grad()\n",
    "    end = min(j+bs1,N_b)\n",
    "    Xn,Xm = torch.tensor(X[pairs[j:end,0]],dtype=torch.float),  torch.tensor(X[pairs[j:end,1]],dtype=torch.float)\n",
    "    Xn , Xm = Variable(Xn, requires_grad=True) , Variable(Xm, requires_grad=True)\n",
    "    Xn = Xn.to(device)\n",
    "    Xm = Xm.to(device)\n",
    "    Yn = sammon(Xn)\n",
    "    Ym = sammon(Xm)\n",
    "    loss1 = EucNorm(Xn-Xm)\n",
    "    loss2 = EucNorm(Yn-Ym)\n",
    "    loss = Loss(loss1,alpha(loss2)[0])\n",
    "    loss.backward()\n",
    "    SammonLoss.append(loss.item())\n",
    "    opt1.step()\n",
    "    opt3.step()\n",
    "    batch1+=1\n",
    "    if(batch1%30 == 0):\n",
    "      print(\"Batch\",batch1,\"/\",(N_b//bs1)+1,\"Sammon Loss :\" , np.mean(SammonLoss))\n",
    "\n",
    "  batch2=0 \n",
    "  RegressorLoss = []\n",
    "  ''' Supervised learning on labelled dataset'''\n",
    "  for k in range(0,N_b2,bs2):\n",
    "    end = min(k+bs2,N_b2)\n",
    "    H1 = H_Train[k:end]\n",
    "    sammon.zero_grad()\n",
    "    \n",
    "    H1 = Variable(H1,requires_grad=True)\n",
    "    H1 = H1.to(device)\n",
    "\n",
    "    Y1 = sammon(H1)\n",
    "    loss_1 = MSE(Y1,Pos_Train[k:end].to(device)).view(-1)\n",
    "    loss_1.backward()\n",
    "    opt1.step()\n",
    "    batch2+=1\n",
    "    RegressorLoss.append(loss_1.item())\n",
    "    if(batch2%20 == 0):\n",
    "      print(\"Batch\",batch2,\"/\",(N_b2//bs2)+1,\"Regressor Loss :\" , np.mean(RegressorLoss))\n",
    "  print(\"Epoch \",i,\"/\",100,\" Sammon Loss :\",np.mean(SammonLoss) ,\" Regressor Loss :\" , np.mean(RegressorLoss))\n",
    "  \n",
    "    \n",
    "  ''' Validation'''  \n",
    "  H_Val = torch.tensor(H_Val,dtype=torch.float)\n",
    "  H_Val = H_Val.to(device)\n",
    "  with torch.no_grad():\n",
    "    Y_Val = sammon(H_Val)\n",
    "    loss_Val = MSE(Y_Val,Pos_Val.to(device)).view(-1)\n",
    "  print(\"Val Loss :\" , loss_Val.item())\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
